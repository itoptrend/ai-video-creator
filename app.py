import streamlit as st
import time
import google.generativeai as genai 
from gtts import gTTS
import os
from PIL import Image
from openai import OpenAI
import requests 
import re
from moviepy.editor import ImageClip, AudioFileClip, VideoFileClip, vfx

# --- 1. CONFIGURATION & CUSTOM CSS (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° 100%) ---
st.set_page_config(page_title="All-in-One AI Creator", page_icon="üé¨", layout="wide")

st.markdown("""
    <style>
    .stApp { background: linear-gradient(135deg, #1e1e2e 0%, #2d2b42 100%); color: #ffffff; }
    .stButton>button { background: linear-gradient(90deg, #ff8a00 0%, #e52e71 100%); color: white; border: none; border-radius: 12px; padding: 10px 24px; font-weight: bold; transition: 0.3s; }
    .stButton>button:hover { transform: scale(1.05); box-shadow: 0 0 15px rgba(229, 46, 113, 0.7); }
    .stTextInput > div > div > input { background-color: #2b2b3d; color: white; border-radius: 8px; border: 1px solid #454555; }
    .stTextArea > div > div > textarea { background-color: #2b2b3d; color: white; border-radius: 8px; }
    .stSelectbox > div > div > div { background-color: #2b2b3d; color: white; }
    div[data-testid="stTooltipHoverTarget"] > svg { color: #ff8a00; }
    .streamlit-expanderHeader { background-color: #2b2b3d; color: #ff8a00; border-radius: 8px; font-weight: bold; }
    .streamlit-expanderContent { background-color: #232333; border-radius: 0 0 8px 8px; }
    div[data-testid="stFileUploader"] section { background-color: #2b2b3d; border: 1px dashed #454555; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { background-color: #2b2b3d; border-radius: 4px 4px 0 0; color: white; }
    .stTabs [aria-selected="true"] { background-color: #ff8a00; color: white; }
    div[role="radiogroup"] > label > div:first-child { background-color: #2b2b3d; border-color: #ff8a00; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. INITIALIZE SESSION STATE ---
if 'step' not in st.session_state: st.session_state.step = 0 
if 'script_options' not in st.session_state: st.session_state.script_options = []
if 'generated_script' not in st.session_state: st.session_state.generated_script = ""
if 'generated_prompt_th' not in st.session_state: st.session_state.generated_prompt_th = ""
if 'generated_image_url' not in st.session_state: st.session_state.generated_image_url = ""
if 'generated_video_url' not in st.session_state: st.session_state.generated_video_url = ""
if 'generated_audio_file' not in st.session_state: st.session_state.generated_audio_file = None
if 'final_video_path' not in st.session_state: st.session_state.final_video_path = None
if 'use_manual_video' not in st.session_state: st.session_state.use_manual_video = False

# --- 3. SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712009.png", width=80)
    st.title("‚öôÔ∏è AI Configuration")
    st.markdown("---")
    
    keys = {}
    keys['gemini'] = st.text_input("Gemini API Key", type="password", help="üîë Google Gemini")
    
    with st.expander("‚ûï ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API ‡∏≠‡∏∑‡πà‡∏ô‡πÜ (Multi-Model Support)"):
        keys['openai'] = st.text_input("OpenAI API Key", type="password", help="üîë OpenAI")
        keys['grok'] = st.text_input("Grok API Key", type="password", help="üîë xAI Grok")
        keys['kling'] = st.text_input("KlingAI API Key", type="password", help="üîë Kling AI")

    st.markdown("---")
    st.markdown("### üß† Model Selection")
    
    model_chat = st.text_input("1. Text Model", value="gemini-1.5-pro-latest", help="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó")
    model_tts = st.text_input("2. TTS Model", value="Google TTS (gTTS)", help="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå")
    model_image = st.text_input("3. Image Gen Model", value="dall-e-3", help="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û") 
    model_video = st.text_input("4. Video AI Model", value="veo-3.0-generate-001", help="‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ AI")
    model_editing = st.text_input("5. Video Editing", value="Python MoviePy", help="Engine ‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠")

    st.markdown("---")
    
    with st.expander("üé® ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Prompt (Prompt Settings)", expanded=True):
        st.caption("‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û")
        
        st.markdown("**1. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏û/‡∏Ñ‡∏•‡∏¥‡∏õ**")
        col_style1, col_style2 = st.columns(2)
        with col_style1: opt_style = st.selectbox("‡∏™‡πÑ‡∏ï‡∏•‡πå", ["‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á (Realistic)", "‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ (Surreal)"])
        with col_style2: opt_aspect = st.selectbox("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô", ["‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏à‡∏±‡∏ï‡∏∏‡∏£‡∏±‡∏™ (1:1)", "‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô (16:9)", "‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á (9:16)"])
        opt_resolution = st.selectbox("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î", ["Standard HD", "Full HD (1080p)", "4K Ultra HD Details"])
        
        st.markdown("**2. ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£**")
        col_char1, col_char2 = st.columns(2)
        with col_char1:
            opt_gender = st.selectbox("‡πÄ‡∏û‡∏®", ["‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏û‡∏®", "‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢", "‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á"])
            opt_skin = st.selectbox("‡∏™‡∏µ‡∏ú‡∏¥‡∏ß", ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "‡∏ú‡∏¥‡∏ß‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏ú‡∏¥‡∏ß‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡∏≠‡∏°‡∏ä‡∏°‡∏û‡∏π", "‡∏ú‡∏¥‡∏ß‡∏™‡∏µ‡πÅ‡∏ó‡∏ô", "‡∏ú‡∏¥‡∏ß‡∏™‡∏µ‡∏Ñ‡∏•‡πâ‡∏≥"]) 
            opt_hair = st.selectbox("‡∏ó‡∏£‡∏á‡∏ú‡∏°", ["‡∏ú‡∏°‡∏™‡∏±‡πâ‡∏ô", "‡∏ú‡∏°‡∏¢‡∏≤‡∏ß", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"])
        with col_char2:
            opt_top = st.selectbox("‡πÄ‡∏™‡∏∑‡πâ‡∏≠", ["‡πÅ‡∏Ç‡∏ô‡∏™‡∏±‡πâ‡∏ô", "‡πÅ‡∏Ç‡∏ô‡∏¢‡∏≤‡∏ß", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"])
            opt_bottom = st.selectbox("‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á/‡∏Å‡∏£‡∏∞‡πÇ‡∏õ‡∏£‡∏á", ["‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á‡∏Ç‡∏≤‡∏™‡∏±‡πâ‡∏ô", "‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á‡∏Ç‡∏≤‡∏¢‡∏≤‡∏ß", "‡∏Å‡∏£‡∏∞‡πÇ‡∏õ‡∏£‡∏á‡∏™‡∏±‡πâ‡∏ô", "‡∏Å‡∏£‡∏∞‡πÇ‡∏õ‡∏£‡∏á‡∏¢‡∏≤‡∏ß", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"])
            opt_count = st.selectbox("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£", ["1 ‡∏Ñ‡∏ô", "2 ‡∏Ñ‡∏ô", "‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 2 ‡∏Ñ‡∏ô"])
            
        st.markdown("**3. ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå**")
        opt_action = st.selectbox("‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥", ["‡∏ô‡∏±‡πà‡∏á", "‡∏¢‡∏∑‡∏ô", "‡∏ô‡∏≠‡∏ô", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"])
        opt_emotion = st.selectbox("‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå", ["‡∏¢‡∏¥‡πâ‡∏°‡∏£‡πà‡∏≤‡πÄ‡∏£‡∏¥‡∏á", "‡πÄ‡∏®‡∏£‡πâ‡∏≤‡∏´‡∏°‡∏≠‡∏á", "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß", "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô", "‡∏ï‡∏Å‡πÉ‡∏à", "‡∏õ‡∏Å‡∏ï‡∏¥"])
        
        st.markdown("**4. ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà**")
        opt_location = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà", ["‡∏ó‡∏∏‡πà‡∏á‡∏ô‡∏≤", "‡∏õ‡πà‡∏≤‡πÄ‡∏Ç‡∏≤‡∏•‡∏≥‡πÄ‡∏ô‡∏≤‡πÑ‡∏û‡∏£", "‡∏ó‡∏∞‡πÄ‡∏•", "‡∏ô‡πâ‡∏≥‡∏ï‡∏Å", "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏≠‡∏ô", "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏•‡πà‡∏ô", "‡∏´‡πâ‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°", "‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "‡∏≠‡∏≠‡∏ü‡∏ü‡∏¥‡∏ï", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"], label_visibility="collapsed")
        
        st.markdown("**5. ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå**")
        opt_voice_gender = st.selectbox("‡πÄ‡∏û‡∏®‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á", ["‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á", "‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢"])

# --- HELPER FUNCTIONS ---
def get_thai_error_message(missing_key, model_name):
    if "openai" in missing_key.lower(): return f"‚ùå **‡πÑ‡∏°‡πà‡∏û‡∏ö OpenAI Key** (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model_name})\n‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Key ‡∏Ç‡∏≠‡∏á OpenAI\n‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Key ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢"
    if "gemini" in missing_key.lower(): return f"‚ùå **‡πÑ‡∏°‡πà‡∏û‡∏ö Gemini Key** (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model_name})\n‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Key ‡∏Ç‡∏≠‡∏á Google\n‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Key ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢"
    if "kling" in missing_key.lower(): return f"‚ùå **‡πÑ‡∏°‡πà‡∏û‡∏ö KlingAI Key**"
    return f"‚ùå Missing {missing_key}"

def validate_model_key(model_name):
    m = model_name.lower()
    if "dall-e" in m or "gpt" in m or "tts-1" in m or "sora" in m:
        if not keys.get('openai'): return False, "OpenAI API Key"
    elif "gemini" in m or "veo" in m or "imagen" in m:
        if not keys.get('gemini'): return False, "Gemini API Key"
    elif "kling" in m:
        if not keys.get('kling'): return False, "KlingAI API Key"
    return True, None

# --- UNIVERSAL ROUTER ---
def generate_text_universal(model_name, prompt, image_inputs=None):
    m = model_name.lower()
    is_valid, missing_key = validate_model_key(model_name)
    if not is_valid: return get_thai_error_message(missing_key, model_name)

    if "gemini" in m:
        try:
            genai.configure(api_key=keys['gemini'])
            model = genai.GenerativeModel(model_name)
            content = [prompt]
            if image_inputs: content.extend(image_inputs); content.append("Context images.")
            response = model.generate_content(content)
            return response.text
        except Exception as e: return f"‚ùå Gemini Error: {e}"
    elif "gpt" in m:
        try:
            client = OpenAI(api_key=keys['openai'])
            res = client.chat.completions.create(model=model_name, messages=[{"role": "user", "content": prompt}])
            return res.choices[0].message.content
        except Exception as e: return f"‚ùå OpenAI Error: {e}"
    elif "kling" in m: return "‚ö†Ô∏è Kling AI ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Text Gen"
    else: return f"‚ùå Unknown model: {model_name}"

def generate_image_universal(model_name, prompt, size_arg="1024x1024"):
    m = model_name.lower()
    is_valid, missing_key = validate_model_key(model_name)
    if not is_valid: return None, get_thai_error_message(missing_key, model_name)

    if "dall-e" in m:
        try:
            client = OpenAI(api_key=keys['openai'])
            res = client.images.generate(model=model_name, prompt=prompt, size=size_arg, n=1)
            return res.data[0].url, None
        except Exception as e: return None, f"‚ùå DALL-E Error: {e}"
    elif "kling" in m:
        time.sleep(1); return f"https://placehold.co/{size_arg.replace('x','/')}?text=Kling+Sim", None
    elif "imagen" in m or "gemini" in m:
        return f"https://placehold.co/{size_arg.replace('x','/')}?text=Gemini+Sim", None
    else: return f"https://placehold.co/{size_arg.replace('x','/')}?text={model_name}", None

def generate_video_ai_universal(model_name, image_path):
    m = model_name.lower()
    is_valid, missing_key = validate_model_key(model_name)
    if not is_valid: return None, get_thai_error_message(missing_key, model_name)
    if "veo" in m or "sora" in m: return None, f"‚ö†Ô∏è {model_name} ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î Public API"
    elif "kling" in m and keys.get('kling'): return None, "‚è≥ Kling API ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ Async Task"
    else: return None, "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Video AI Key"

def generate_audio_universal(model_name, text, gender_selection):
    m = model_name.lower()
    output_file = "generated_audio.mp3"
    if "openai" in m or "tts-1" in m:
        is_valid, missing_key = validate_model_key(model_name)
        if not is_valid: return None, get_thai_error_message(missing_key, model_name)

    if ("tts-1" in m or "openai" in m) and keys['openai']:
        try:
            client = OpenAI(api_key=keys['openai'])
            voice_id = "nova"
            if "‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢" in gender_selection: voice_id = "onyx"
            response = client.audio.speech.create(model=model_name, voice=voice_id, input=text)
            response.stream_to_file(output_file)
            return output_file, None
        except Exception as e: return None, f"OpenAI TTS Error: {e}"
    else:
        try:
            tts = gTTS(text=text, lang='th')
            tts.save(output_file)
            return output_file, None
        except Exception as e: return None, f"Google TTS Error: {e}"

# --- 4. MAIN INTERFACE ---
st.title("üé¨ All-in-One AI Content Generator")
col1, col2 = st.columns([1, 2])

# --- COLUMN 1: INPUTS ---
with col1:
    st.subheader("1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ & ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    topic_options = ["1. ‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "2. ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏•‡πà‡∏≤‡∏û‡∏£‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á", "3. ‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡πÅ‡∏™", "4. ‡∏Ñ‡∏≥‡∏Ñ‡∏°‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô", "5. ‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢", "6. ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "7. ‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏", "8. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏î Forex XAUUSD"]
    selected_topic = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ò‡∏µ‡∏°‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå:", topic_options)
    
    uploaded_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    image_objs = []
    if uploaded_files:
        st.caption(f"üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß {len(uploaded_files)} ‡πÑ‡∏ü‡∏•‡πå")
        cols = st.columns(3)
        for i, file in enumerate(uploaded_files):
            if i < 3: cols[i].image(file, use_container_width=True)
            image_objs.append(Image.open(file))

    st.markdown("""
    <div style="background-color: #2b2b3d; padding: 10px; border-radius: 8px; margin-bottom: 10px; font-size: 0.9em; color: #e0e0e0; border: 1px solid #454555;">
        <strong>üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Prompt:</strong><br>
        ‚Ä¢ <b>‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®/‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå:</b> (‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô, ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢, ‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö)<br>
        ‚Ä¢ <b>‡πÅ‡∏™‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏µ:</b> (‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏™‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏ô‡∏µ‡∏≠‡∏≠‡∏ô, ‡πÇ‡∏ó‡∏ô‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô)<br>
        ‚Ä¢ <b>‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô:</b> (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤, ‡πÇ‡∏Ñ‡∏•‡∏™‡∏≠‡∏±‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤, ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡πÇ‡∏î‡∏£‡∏ô)
    </div>
    """, unsafe_allow_html=True)

    user_description = st.text_area("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°", height=100)
    duration = st.select_slider("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)", options=[5, 8, 10, 15], value=10)
    
    if st.button("‚ú® ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó (Start Script Generation)", use_container_width=True):
        if not any(keys.values()):
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏Ñ‡πà‡∏≤‡∏¢")
        else:
            with st.spinner(f"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏î‡πâ‡∏ß‡∏¢ {model_chat}..."):
                
                # [FIXED] ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≤‡∏Å Sidebar ‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà Step 1
                sidebar_specs = f"""
                - ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏†‡∏≤‡∏û: {opt_style}
                - ‡πÄ‡∏û‡∏®‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£: {opt_gender}
                - ‡∏™‡∏µ‡∏ú‡∏¥‡∏ß: {opt_skin}
                - ‡∏ó‡∏£‡∏á‡∏ú‡∏°: {opt_hair}
                - ‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤: {opt_top} (‡∏ó‡πà‡∏≠‡∏ô‡∏ö‡∏ô) / {opt_bottom} (‡∏ó‡πà‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á)
                - ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥: {opt_action}
                - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {opt_emotion}
                - ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà: {opt_location}
                """

                prompt = f"""
                ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: Creative Director. 
                
                ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡πÄ‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏â‡∏≤‡∏Å):
                ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: '{selected_topic}'
                ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: '{user_description}'
                ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡∏â‡∏≤‡∏Å:
                {sidebar_specs}
                
                ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô "Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û" ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏â‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏° "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡∏â‡∏≤‡∏Å" ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î ‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ "IMAGE_PROMPT_TH:"
                ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏™‡∏±‡πâ‡∏ô‡πÜ (Voiceover only) ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 3 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (3 Options) ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÉ‡∏´‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ "SCRIPTS:" ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏±‡πà‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏î‡πâ‡∏ß‡∏¢ "|||"
                
                ***‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:*** ‡πÉ‡∏™‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏û‡∏π‡∏î "..." ‡∏Ñ‡∏£‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
                """
                script_result = generate_text_universal(model_chat, prompt, image_objs if image_objs else None)
                
                if "Error" in script_result or "‚ùå" in script_result:
                    st.error(script_result)
                else:
                    img_prompt_th = ""
                    scripts_part = script_result
                    
                    if "IMAGE_PROMPT_TH:" in script_result and "SCRIPTS:" in script_result:
                        parts = script_result.split("SCRIPTS:")
                        img_prompt_th = parts[0].replace("IMAGE_PROMPT_TH:", "").strip()
                        scripts_part = parts[1]
                    
                    options = scripts_part.split("|||")
                    options = [opt.strip() for opt in options if opt.strip()]
                    if len(options) == 0: options = [scripts_part]
                    
                    st.session_state.generated_prompt_th = img_prompt_th
                    st.session_state.script_options = options
                    st.session_state.step = 1
                    st.rerun()

# --- COLUMN 2: RESULTS (UI ‡πÄ‡∏î‡∏¥‡∏°) ---
with col2:
    st.subheader("2. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Real-time)")
    step_container = st.container()

    # --- STEP 1: Script Selection ---
    with step_container:
        with st.expander(f"‚úÖ Step 1: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå (Model: {model_chat})", expanded=(st.session_state.step >= 1)):
            if st.session_state.step >= 1 and st.session_state.script_options:
                
                if st.session_state.generated_prompt_th:
                    st.markdown("##### üñºÔ∏è ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°/Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)")
                    st.info(st.session_state.generated_prompt_th)
                
                st.divider()
                st.info(f"üéâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å {len(st.session_state.script_options)} ‡πÅ‡∏ö‡∏ö:")
                tabs = st.tabs([f"‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà {i+1}" for i in range(len(st.session_state.script_options))])
                
                for i, tab in enumerate(tabs):
                    with tab:
                        st.text_area(f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà {i+1}", value=st.session_state.script_options[i], height=200, key=f"script_opt_{i}")
                        if st.button(f"‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà {i+1} ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠", key=f"btn_sel_{i}"):
                            st.session_state.generated_script = st.session_state.script_options[i]
                            st.session_state.step = 2 
                            st.rerun()
            
            elif st.session_state.step == 0:
                st.markdown("<div style='text-align: center; color: gray; padding: 20px;'>‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó' ...</div>", unsafe_allow_html=True)
            
            if st.session_state.step >= 2:
                st.success("‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß")
                new_script = st.text_area("‡∏ö‡∏ó‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (Final Edit):", value=st.session_state.generated_script, height=150)
                if new_script != st.session_state.generated_script:
                    st.session_state.generated_script = new_script

                quotes_found = re.findall(r'"(.*?)"', new_script, re.DOTALL)
                radio_options = ["‡∏û‡∏≤‡∏Å‡∏¢‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (All Text)"]
                if quotes_found:
                    for idx, q in enumerate(quotes_found): radio_options.append(f'‡∏ó‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà {idx+1}: "{q}"')
                
                selected_voice_opt = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏≤‡∏Å‡∏¢‡πå:", radio_options)
                
                if st.button("üöÄ ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡πÅ‡∏•‡∏∞ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (Audio/Image/Video)"):
                    with st.spinner("üéôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå..."):
                        final_text = new_script.replace('*', '')
                        if "‡∏û‡∏≤‡∏Å‡∏¢‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" not in selected_voice_opt:
                            final_text = selected_voice_opt.split('"', 1)[1].rsplit('"', 1)[0]
                        
                        audio_path, err = generate_audio_universal(model_tts, final_text, opt_voice_gender)
                        if audio_path: st.session_state.generated_audio_file = audio_path
                        else: st.warning(f"Audio Error: {err}")

                    with st.spinner(f"üé® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ {model_image}..."):
                        dalle_size_param = "1024x1024"
                        if "16:9" in opt_aspect: dalle_size_param = "1792x1024"
                        elif "9:16" in opt_aspect: dalle_size_param = "1024x1792"

                        # Use the detailed Thai prompt generated in Step 1
                        base_prompt = st.session_state.generated_prompt_th if st.session_state.generated_prompt_th else new_script[:100]
                        full_img_prompt = f"Write a {model_image} image prompt based on description: '{base_prompt}'. Style: {opt_style}, Quality: {opt_resolution}. Photorealistic."
                        
                        img_prompt_res = generate_text_universal(model_chat, full_img_prompt)
                        img_url, err = generate_image_universal(model_image, img_prompt_res, dalle_size_param)
                        
                        if img_url:
                            st.session_state.generated_image_url = img_url
                            if img_url.startswith("http"):
                                try:
                                    img_data = requests.get(img_url).content
                                    with open("temp_image.png", 'wb') as h: h.write(img_data)
                                except: pass
                        else:
                            st.error(f"Image Gen Failed: {err}")

                    with st.spinner(f"üéûÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Motion Video..."):
                        if os.path.exists("temp_image.png"):
                            vid_url, vid_err = generate_video_ai_universal(model_video, "temp_image.png")
                            if vid_url: st.session_state.generated_video_url = vid_url
                            else: 
                                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Motion Video: {vid_err} (‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á‡πÅ‡∏ó‡∏ô)")
                                st.session_state.generated_video_url = None
                    
                    st.session_state.process_complete = True 
                    st.success("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß!")
                    st.rerun()

    # --- STEP 2-5 ---
    if st.session_state.step >= 2:
        
        # Step 2
        with step_container:
            with st.expander(f"‚úÖ Step 2: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå (Model: {model_tts})", expanded=False):
                if st.session_state.generated_audio_file: st.audio(st.session_state.generated_audio_file)
                else: st.info("‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")

        # Step 3
        with step_container:
            with st.expander(f"‚úÖ Step 3: ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (Model: {model_image})", expanded=False):
                st.markdown("**1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ AI)**")
                manual_upload = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û (JPG, PNG)", type=['png', 'jpg', 'jpeg'], key="img_up")
                if manual_upload:
                    image = Image.open(manual_upload)
                    image.save("temp_image.png")
                    st.session_state.generated_image_url = "uploaded"
                    st.image(image, caption="Uploaded Image")
                    st.success("‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß")

                st.markdown("---")
                st.markdown("**2. ‡∏´‡∏£‡∏∑‡∏≠ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ AI**")
                if st.session_state.generated_image_url and not manual_upload:
                    st.image(st.session_state.generated_image_url, caption="AI Generated Image")
                
                regen_model = st.text_input("‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Model ‡∏†‡∏≤‡∏û:", value=model_image, key="regen_img_key")
                if st.button("üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà"):
                    is_valid, missing = validate_model_key(regen_model)
                    if not is_valid: st.error(get_thai_error_message(missing, regen_model))
                    else:
                        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ {regen_model}..."):
                            dalle_size = "1024x1024"
                            if "16:9" in opt_aspect: dalle_size = "1792x1024"
                            elif "9:16" in opt_aspect: dalle_size = "1024x1792"
                            
                            base_p = st.session_state.generated_prompt_th if st.session_state.generated_prompt_th else selected_topic
                            img_res = generate_image_universal(regen_model, f"Scene: {base_p}, {opt_style}", dalle_size)
                            
                            if img_res[0]:
                                st.session_state.generated_image_url = img_res[0]
                                if img_res[0].startswith("http"):
                                    try:
                                        r = requests.get(img_res[0])
                                        with open("temp_image.png", 'wb') as f: f.write(r.content)
                                    except: pass
                                st.success("‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                                time.sleep(0.5)
                                st.rerun()
                            else: st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {img_res[1]}")

        # Step 4
        with step_container:
            with st.expander(f"‚úÖ Step 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ß‡∏µ‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß (Model: {model_video})", expanded=False):
                st.markdown("**1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)**")
                manual_vid = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (MP4, MOV)", type=['mp4', 'mov'], key="vid_up")
                if manual_vid:
                    with open("temp_video.mp4", "wb") as f: f.write(manual_vid.read())
                    st.session_state.use_manual_video = True
                    st.video("temp_video.mp4")
                    st.success("‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß")

                st.markdown("---")
                st.markdown("**2. ‡∏´‡∏£‡∏∑‡∏≠ ‡∏™‡∏£‡πâ‡∏≤‡∏á Motion Video ‡∏î‡πâ‡∏ß‡∏¢ AI**")
                if st.session_state.generated_video_url and not manual_vid: 
                    st.success("‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ AI ‡πÅ‡∏•‡πâ‡∏ß")
                else: st.info("‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á‡πÅ‡∏ó‡∏ô (‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠)")
                
                regen_video_model = st.text_input("‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Model ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠:", value=model_video, key="regen_vid_key")
                
                if st.button("üéûÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á Motion Video ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"):
                    is_valid, missing = validate_model_key(regen_video_model)
                    if not is_valid: st.error(get_thai_error_message(missing, regen_video_model))
                    else:
                        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏î‡πâ‡∏ß‡∏¢ {regen_video_model}..."):
                            vid_url, vid_err = generate_video_ai_universal(regen_video_model, "temp_image.png")
                            if vid_url:
                                st.session_state.generated_video_url = vid_url
                                st.session_state.use_manual_video = False
                                st.success("‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                            else: st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {vid_err}")

        st.divider()
        
        # Step 5
        st.markdown(f"### üé¨ Final Video Generation")
        col_btn1, col_btn2 = st.columns([1.5, 1])
        with col_btn1:
            if st.button("üé• ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (Render Real Video)", type="primary", use_container_width=True):
                if os.path.exists("temp_image.png") and os.path.exists("generated_audio.mp3"):
                    with st.spinner("Rendering..."):
                        try:
                            audio_clip = AudioFileClip("generated_audio.mp3")
                            has_video = False
                            if st.session_state.use_manual_video and os.path.exists("temp_video.mp4"):
                                has_video = True
                            
                            if has_video:
                                visual_clip = VideoFileClip("temp_video.mp4")
                                if visual_clip.duration < audio_clip.duration:
                                    visual_clip = vfx.loop(visual_clip, duration=audio_clip.duration)
                                else:
                                    visual_clip = visual_clip.subclip(0, audio_clip.duration)
                            else:
                                visual_clip = ImageClip("temp_image.png").set_duration(audio_clip.duration)
                            
                            if "9:16" in opt_aspect: visual_clip = visual_clip.resize(height=1920)
                            
                            final_clip = visual_clip.set_audio(audio_clip)
                            final_clip.write_videofile("final_output.mp4", fps=24, codec="libx264", audio_codec="aac")
                            st.session_state.final_video_path = "final_output.mp4"
                            st.success("Done!")
                        except Exception as e: st.error(f"Render Error: {e}")
                else: st.error("Missing Assets")
        
        if st.session_state.final_video_path:
            st.video(st.session_state.final_video_path)
            with open(st.session_state.final_video_path, "rb") as f:
                st.download_button("‚¨áÔ∏è Download MP4", f, "video.mp4")

        with col_btn2:
            if st.button("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", use_container_width=True):
                st.session_state.clear()
                st.rerun()